{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "segmented_data = parent_dir + \"/data/interim/parse_filtered\"\n",
    "sys.path.append(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_data_paths = os.listdir(segmented_data)\n",
    "seg_data_paths = [segmented_data + '/' + s for s in seg_data_paths]\n",
    "\n",
    "for subject in seg_data_paths:\n",
    "    # Create folder for each subject to save nomalized data into\n",
    "    save_dir = parent_dir + \"/data/interim/normalized\"\n",
    "    if not os.path.exists(save_dir + f\"/{os.path.basename(os.path.normpath(subject))}\"):\n",
    "        os.makedirs(save_dir + f\"/{os.path.basename(os.path.normpath(subject))}\")\n",
    "        \n",
    "    # Determine number of activities in subject segmented data\n",
    "    # Read files in subject folder of parsed filtered segmented data\n",
    "    activities = os.listdir(subject)\n",
    "    \n",
    "    # Open pkl file of activity\n",
    "    for activity in activities:\n",
    "        with open(subject + '/' + activity, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            \n",
    "        # Nomalize data of activity\n",
    "        data_norm = data\n",
    "        data_norm['time'] = data['time']\n",
    "        data_norm['ecg'] = (data['ecg'] - np.min(data['ecg'])) / (np.max(data['ecg']) - np.min(data['ecg']))\n",
    "        data_norm['ppg_ir_1'] = (data['ppg_ir_1'] - np.min(data['ppg_ir_1'])) / (np.max(data['ppg_ir_1']) - np.min(data['ppg_ir_1']))\n",
    "        data_norm['ppg_r_1'] = (data['ppg_r_1'] - np.min(data['ppg_r_1'])) / (np.max(data['ppg_r_1']) - np.min(data['ppg_r_1']))\n",
    "        data_norm['ppg_g_1'] = (data['ppg_g_1'] - np.min(data['ppg_g_1'])) / (np.max(data['ppg_g_1']) - np.min(data['ppg_g_1']))\n",
    "        data_norm['ppg_ir_2'] = (data['ppg_ir_2'] - np.min(data['ppg_ir_2'])) / (np.max(data['ppg_ir_2']) - np.min(data['ppg_ir_2']))\n",
    "        data_norm['ppg_r_2'] = (data['ppg_r_2'] - np.min(data['ppg_r_2'])) / (np.max(data['ppg_r_2']) - np.min(data['ppg_r_2']))\n",
    "        data_norm['ppg_g_2'] = (data['ppg_g_2'] - np.min(data['ppg_g_2'])) / (np.max(data['ppg_g_2']) - np.min(data['ppg_g_2']))\n",
    "        data_norm['scg_LT'] = (data['scg_LT'] - np.min(data['scg_LT'])) / (np.max(data['scg_LT']) - np.min(data['scg_LT']))\n",
    "        data_norm['scg_HF'] = (data['scg_HF'] - np.min(data['scg_HF'])) / (np.max(data['scg_HF']) - np.min(data['scg_HF']))\n",
    "        data_norm['scg_DV'] = (data['scg_DV'] - np.min(data['scg_DV'])) / (np.max(data['scg_DV']) - np.min(data['scg_DV']))\n",
    "        data_norm['pcg_DV'] = (data['pcg_DV'] - np.min(data['pcg_DV'])) / (np.max(data['pcg_DV']) - np.min(data['pcg_DV']))\n",
    "\n",
    "        # Save pkl file of activity\n",
    "        with open (f\"{save_dir}/{os.path.basename(os.path.normpath(subject))}/{activity}\", \"wb\") as f:\n",
    "            pickle.dump(data_norm, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mims-transformer-stress-classification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
