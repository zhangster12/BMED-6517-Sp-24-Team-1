{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading completed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Constants\n",
    "DIR_PATH = '../Consolidated_Features'\n",
    "SUBJECT_LIST = [\n",
    "    \"3128\", \"3129\", \"3130\", \"3131\", \"3132\", \"3133\", \"3136\", \"3137\", \"3138\", \"3139\", \n",
    "    \"3140\", \"3141\", \"3142\", \"3143\", \"3147\", \"3148\", \"3149\", \"3150\", \"3151\", \"3152\", \n",
    "    \"3153\", \"3154\", \"3155\", \"3156\", \"3158\", \"3159\", \"3160\", \"3162\", \"6037\", \"6038\", \n",
    "    \"6043\", \"6044\", \"6045\", \"6046\", \"6047\", \"6048\", \"6049\"\n",
    "]\n",
    "NUM_STIMULI = 5\n",
    "STIMULUS_TYPES = ['Rest', 'Reading', 'SpeechPrep', 'Speech', 'Recovery']\n",
    "NUM_FEATURES = 5\n",
    "FEATURE_TYPES = ['HR', 'PAT', 'PEP', 'PPGamp', 'PTTrecip']\n",
    "\n",
    "# List to store dataframes for MI subjects\n",
    "dataframes_mi = []\n",
    "\n",
    "# List to store dataframes for healthy control subjects\n",
    "dataframes_ht = []\n",
    "\n",
    "# List to store dataframes for all subjects\n",
    "dataframes_all = []\n",
    "\n",
    "# Variables to track index of MI, healthy control, and all subjects\n",
    "sub_mi = -1\n",
    "sub_ht = -1\n",
    "sub_all = -1\n",
    "\n",
    "# Loop through all subjects\n",
    "for sub in os.listdir(DIR_PATH):\n",
    "    subject_id = int(sub[3:])  # Extract subject ID from directory name\n",
    "\n",
    "    if str(subject_id) in SUBJECT_LIST:\n",
    "\n",
    "        # Check if the subject ID belongs to MI subjects\n",
    "        if str(subject_id).startswith('3'):\n",
    "            sub_mi += 1\n",
    "            dataframes_mi.append([])\n",
    "\n",
    "            # Loop through stimuli\n",
    "            for stim in range(NUM_STIMULI):\n",
    "                dataframes_mi[sub_mi].append([])\n",
    "\n",
    "                # Loop through features\n",
    "                for feat in range(NUM_FEATURES):\n",
    "                    dataframes_mi[sub_mi][stim].append([])\n",
    "                    feat_load = os.path.join(DIR_PATH, 'sub' + str(subject_id), 'stim' + str(stim) + '_' + FEATURE_TYPES[feat] + '.csv')\n",
    "                    data = pd.read_csv(feat_load)\n",
    "                    dataframes_mi[sub_mi][stim][feat] = data.values\n",
    "        \n",
    "        # Check if the subject ID belongs to healthy control subjects\n",
    "        elif str(subject_id).startswith('6'):\n",
    "            sub_ht += 1\n",
    "            dataframes_ht.append([])\n",
    "\n",
    "            # Loop through stimuli\n",
    "            for stim in range(NUM_STIMULI):\n",
    "                dataframes_ht[sub_ht].append([])\n",
    "\n",
    "                # Loop through features\n",
    "                for feat in range(NUM_FEATURES):\n",
    "                    dataframes_ht[sub_ht][stim].append([])\n",
    "                    feat_load = os.path.join(DIR_PATH, 'sub' + str(subject_id), 'stim' + str(stim) + '_' + FEATURE_TYPES[feat] + '.csv')\n",
    "                    data = pd.read_csv(feat_load)\n",
    "                    dataframes_ht[sub_ht][stim][feat] = data.values\n",
    "        \n",
    "        # For all subjects\n",
    "        sub_all += 1\n",
    "        dataframes_all.append([])\n",
    "\n",
    "        # Loop through stimuli\n",
    "        for stim in range(NUM_STIMULI):\n",
    "            dataframes_all[sub_all].append([])\n",
    "\n",
    "            # Loop through features\n",
    "            for feat in range(NUM_FEATURES):\n",
    "                dataframes_all[sub_all][stim].append([])\n",
    "                feat_load = os.path.join(DIR_PATH, 'sub' + str(subject_id), 'stim' + str(stim) + '_' + FEATURE_TYPES[feat] + '.csv')\n",
    "                data = pd.read_csv(feat_load)\n",
    "                dataframes_all[sub_all][stim][feat] = data.values\n",
    "\n",
    "print(\"Data loading completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get unhealthy vs. healthy labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine MI (Myocardial Infarction) vs. HT (Healthy Control) status based on subject identifier\n",
    "mi_subjects = [\"3128\", \"3129\", \"3130\", \"3131\", \"3132\", \"3133\", \"3136\", \"3137\", \"3138\", \"3139\", \n",
    "               \"3140\", \"3141\", \"3142\", \"3143\", \"3147\", \"3148\", \"3149\", \"3150\", \"3151\", \"3152\", \n",
    "               \"3153\", \"3154\", \"3155\", \"3156\", \"3158\", \"3159\", \"3160\", \"3162\"]\n",
    "\n",
    "# Healthy Control subjects\n",
    "ht_subjects = [\"6037\", \"6038\", \"6043\", \"6044\", \"6045\", \"6046\", \"6047\", \"6048\", \"6049\"]\n",
    "\n",
    "# Initialization of lists to store health condition labels\n",
    "health_condition_labels = []\n",
    "\n",
    "# Modify the loop to assign labels based on health condition\n",
    "for subj_index, subj_id in enumerate(SUBJECT_LIST):\n",
    "\n",
    "    if subj_id in mi_subjects:\n",
    "        health_condition = 0  # Myocardial Infarction\n",
    "\n",
    "    elif subj_id in ht_subjects:\n",
    "        health_condition = 1  # Healthy Control\n",
    "        \n",
    "    else:\n",
    "        health_condition = \"Unknown\"\n",
    "    \n",
    "    # Create labels based on health condition for all stimuli and features\n",
    "    subj_labels = []\n",
    "\n",
    "    for _ in range(NUM_STIMULI):\n",
    "        stim_labels = []\n",
    "\n",
    "        for _ in range(NUM_FEATURES):\n",
    "            stim_labels.append(health_condition)\n",
    "\n",
    "        subj_labels.append(stim_labels)\n",
    "        \n",
    "    health_condition_labels.append(subj_labels)\n",
    "\n",
    "# Now, health_condition_labels contains labels for each subject, stimulus, and feature based on health condition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize to baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dyzha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\dyzha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\_methods.py:131: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret / rcount\n"
     ]
    }
   ],
   "source": [
    "# %% Baseline correction (normalization)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Initialize lists to store mean difference, normalized data, and labels\n",
    "mean_difference_all = []  # Stores the mean difference between feature and baseline for all subjects, stimuli, and features\n",
    "normalized_data_all = []  # Stores the normalized data for all subjects, stimuli, and features\n",
    "labels_all = []  # Stores the labels for all subjects, stimuli, and features\n",
    "\n",
    "# Number of data points and half of it\n",
    "num_data_points = 80  # Total number of data points\n",
    "data_points_half = round(num_data_points / 2)  # Half of the total number of data points\n",
    "\n",
    "# Loop through each subject\n",
    "for subject_index, subject_id in enumerate(SUBJECT_LIST):\n",
    "    normalized_data_subject = []  # Stores the normalized data for the current subject\n",
    "    labels_subject = []  # Stores the labels for the current subject\n",
    "\n",
    "    # Loop through each stimulus\n",
    "    for stimulus_index in range(NUM_STIMULI):\n",
    "        normalized_data_stimulus = []  # Stores the normalized data for the current stimulus\n",
    "        labels_stimulus = []  # Stores the labels for the current stimulus\n",
    "\n",
    "        # Loop through each feature\n",
    "        for feature_index in range(NUM_FEATURES):\n",
    "            baseline_data = dataframes_all[subject_index][0][feature_index][:, 1]  # Baseline data\n",
    "            baseline_midpoint = baseline_data[len(baseline_data) // 2 - data_points_half:len(baseline_data) // 2 + data_points_half]  # Midpoint of baseline data\n",
    "            feature_data = dataframes_all[subject_index][stimulus_index][feature_index][:, 1]  # Feature data\n",
    "            feature_midpoint = feature_data[len(feature_data) // 2 - data_points_half:len(feature_data) // 2 + data_points_half]  # Midpoint of feature data\n",
    "\n",
    "            # Calculate mean difference between feature and baseline\n",
    "            mean_difference = (np.mean(feature_midpoint) - np.mean(baseline_midpoint)) / np.mean(baseline_midpoint)\n",
    "            mean_difference_all.append(mean_difference)\n",
    "\n",
    "            # Normalize the data and assign labels\n",
    "            if stimulus_index == 0:\n",
    "                # Baseline data\n",
    "                normalized_data = (baseline_midpoint - np.mean(baseline_midpoint)) / np.mean(baseline_midpoint)\n",
    "                labels = np.zeros_like(normalized_data)  # Assign label 0\n",
    "\n",
    "            else:\n",
    "                # Feature data\n",
    "                normalized_data = (feature_midpoint - np.mean(baseline_midpoint)) / np.mean(baseline_midpoint)\n",
    "                labels = np.ones_like(normalized_data)  # Assign label 1\n",
    "\n",
    "            normalized_data_stimulus.append(normalized_data)\n",
    "            labels_stimulus.append(labels)\n",
    "\n",
    "        normalized_data_subject.append(normalized_data_stimulus)\n",
    "        labels_subject.append(labels_stimulus)\n",
    "\n",
    "    normalized_data_all.append(normalized_data_subject)\n",
    "    labels_all.append(labels_subject)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get normalized data for SpeechPrep for all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_prep_normalized_all = [subject_data[STIMULUS_TYPES.index('SpeechPrep')] for subject_data in normalized_data_all]\n",
    "speech_prep_labels_all = [subject_labels[STIMULUS_TYPES.index('SpeechPrep')] for subject_labels in health_condition_labels]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
