{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.signal import butter, filtfilt, resample \n",
    "\n",
    "# Set up directory and file paths\n",
    "dir = '../Consolidated_Features'\n",
    "Subject = os.listdir(dir)\n",
    "NumSub = np.size(Subject)\n",
    "subj_list = [\n",
    "    \"3128\", \"3129\", \"3130\", \"3131\", \"3132\", \"3133\", \"3136\", \"3137\", \"3138\", \"3139\", \n",
    "    \"3140\", \"3141\", \"3142\", \"3143\", \"3147\", \"3148\", \"3149\", \"3150\", \"3151\", \"3152\", \n",
    "    \"3153\", \"3154\", \"3155\", \"3156\", \"3158\", \"3159\", \"3160\", \"3162\", \"6037\", \"6038\", \n",
    "    \"6043\", \"6044\", \"6045\", \"6046\", \"6047\", \"6048\", \"6049\"\n",
    "]\n",
    "\n",
    "NumStim = 5\n",
    "Stimulus = ['Rest', 'Reading', 'SpeechPrep', 'Speech', 'Recovery']\n",
    "NumFeat = 5\n",
    "Feature = ['HR', 'PAT', 'PEP', 'PPGamp', 'PTTrecip']\n",
    "\n",
    "# Sort subject IDs\n",
    "Subj = np.zeros(len(Subject))\n",
    "for i in range(len(Subject)):\n",
    "    Subj[i] = int(Subject[i][3:])  \n",
    "Subj.sort()\n",
    "\n",
    "# Initialize dataframes for different groups\n",
    "dataframes_MI = []\n",
    "dataframes_Ht = []\n",
    "dataframes_all = []\n",
    "\n",
    "sub_MI = -1\n",
    "sub_Ht = -1\n",
    "sub_all = -1\n",
    "\n",
    "# Load data for each subject into corresponding dataframes\n",
    "for sub in range(NumSub):\n",
    "\n",
    "    # Check if the subject is in the list of subjects to process\n",
    "    if str(round(Subj[sub])) in subj_list:\n",
    "\n",
    "        # Check if the subject ID starts with '3', indicating a patient\n",
    "        if str(Subj[sub]).startswith('3'):\n",
    "            sub_MI += 1\n",
    "            dataframes_MI.append([])\n",
    "\n",
    "            # Iterate over stimuli\n",
    "            for stim in range(NumStim):\n",
    "                dataframes_MI[sub_MI].append([])\n",
    "\n",
    "                # Iterate over features\n",
    "                for feat in range(NumFeat):\n",
    "                    dataframes_MI[sub_MI][stim].append([]) \n",
    "                    # Load feature data from CSV file and store it in the corresponding dataframe\n",
    "                    Feat_load = os.path.join(dir, 'sub' + str(int(Subj[sub])), 'stim' + str(stim) + '_' + Feature[feat] + '.csv')\n",
    "                    data = pd.read_csv(Feat_load)\n",
    "                    dataframes_MI[sub_MI][stim][feat] = data.values\n",
    "\n",
    "        # Check if the subject ID starts with '6', indicating a healthy control\n",
    "        if str(Subj[sub]).startswith('6'):\n",
    "            sub_Ht += 1\n",
    "            dataframes_Ht.append([])\n",
    "\n",
    "            # Iterate over stimuli\n",
    "            for stim in range(NumStim):\n",
    "                dataframes_Ht[sub_Ht].append([])\n",
    "\n",
    "                # Iterate over features\n",
    "                for feat in range(NumFeat):\n",
    "                    dataframes_Ht[sub_Ht][stim].append([])\n",
    "                    # Load feature data from CSV file and store it in the corresponding dataframe\n",
    "                    Feat_load = os.path.join(dir, 'sub' + str(int(Subj[sub])), 'stim' + str(stim) + '_' + Feature[feat] + '.csv')\n",
    "                    data = pd.read_csv(Feat_load)\n",
    "                    dataframes_Ht[sub_Ht][stim][feat] = data.values\n",
    "\n",
    "# Load data for all subjects into a single dataframe\n",
    "for sub in range(NumSub):\n",
    "\n",
    "    # Check if the subject is in the list of subjects to process\n",
    "    if str(round(Subj[sub])) in subj_list:\n",
    "        sub_all += 1\n",
    "        dataframes_all.append([]) \n",
    "\n",
    "        # Iterate over stimuli\n",
    "        for stim in range(NumStim):\n",
    "            dataframes_all[sub_all].append([]) \n",
    "\n",
    "            # Iterate over features\n",
    "            for feat in range(NumFeat):\n",
    "                dataframes_all[sub_all][stim].append([]) \n",
    "                # Load feature data from CSV file and store it in the corresponding dataframe\n",
    "                Feat_load = os.path.join(dir, 'sub' + str(int(Subj[sub])), 'stim' + str(stim) + '_' + Feature[feat] + '.csv')\n",
    "                data = pd.read_csv(Feat_load)\n",
    "                dataframes_all[sub_all][stim][feat] = data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine healthy vs. non-healthy status based on subject identifier\n",
    "healthy_subjects = [\"6037\", \"6038\", \"6043\", \"6044\", \"6045\", \"6046\", \"6047\", \"6048\", \"6049\"]\n",
    "# Assuming all subjects not in the above list are considered non-healthy\n",
    "non_healthy_subjects = [subj for subj in subj_list if subj not in healthy_subjects]\n",
    "\n",
    "# Initialization of lists to store labels\n",
    "data_labels = []\n",
    "\n",
    "# Modify the loop to assign labels based on health status\n",
    "\n",
    "for subj_index, subj_id in enumerate(subj_list):\n",
    "\n",
    "    if subj_id in healthy_subjects:\n",
    "        health_status = 1  # Healthy\n",
    "\n",
    "    else:\n",
    "        health_status = 0  # Non-healthy\n",
    "\n",
    "    # Create labels based on health status for all stimuli and features\n",
    "    subj_labels = []\n",
    "\n",
    "    for _ in range(NumStim):\n",
    "        stim_labels = []\n",
    "\n",
    "        for _ in range(NumFeat):\n",
    "            stim_labels.append(health_status)\n",
    "        subj_labels.append(stim_labels)\n",
    "        \n",
    "    data_labels.append(subj_labels)\n",
    "\n",
    "# Now, data_labels contains labels for each subject, stimulus, and feature based on health status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def access_df(df, participant_index, stimulus_index, feature_index):\n",
    "    data = df[participant_index][stimulus_index][feature_index]\n",
    "    time = data[:, 0]\n",
    "    feat_values = data[:, 1]\n",
    "    return time, feat_values\n",
    "\n",
    "def join_stimulus(df, participant_index, feature_index):\n",
    "    time = []\n",
    "    feat_values = []\n",
    "\n",
    "    for stimulus_index in range(NumStim):\n",
    "        data = df[participant_index][stimulus_index][feature_index]\n",
    "        time_temp = data[:, 0]\n",
    "        values = data[:, 1]\n",
    "        time.append(time_temp)\n",
    "        feat_values.append(values)\n",
    "    \n",
    "    time = np.concatenate(time)\n",
    "    feat_values = np.concatenate(feat_values)\n",
    "\n",
    "    return time, feat_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Baseline correction (normalization)\n",
    "mean_all = []\n",
    "data_all = []\n",
    "data_y_all = []\n",
    "num_data = 80\n",
    "dp = round(num_data / 2)\n",
    "\n",
    "for subj in range(len(subj_list)):\n",
    "    data_all.append([]) \n",
    "    data_y_all.append([]) \n",
    "\n",
    "    for stim in range(2):\n",
    "        data_all[subj].append([]) \n",
    "        data_y_all[subj].append([]) \n",
    "\n",
    "        for feat in range(NumFeat):\n",
    "            data_all[subj][stim].append([]) \n",
    "            data_y_all[subj][stim].append([]) \n",
    "            baseline = dataframes_all[subj][0][feat][:, 1]\n",
    "            baseline_mid = baseline[round(len(baseline) / 2) - dp:round(len(baseline) / 2) + dp] \n",
    "            feature = dataframes_all[subj][2][feat][:, 1]\n",
    "            feature_mid = feature[round(len(feature) / 2) - dp:round(len(feature) / 2) + dp]\n",
    "            mean_all.append((np.mean(feature_mid) - np.mean(baseline_mid)) / np.mean(baseline_mid))\n",
    "\n",
    "            if stim == 0:\n",
    "                data_all[subj][stim][feat] = (baseline_mid - np.mean(baseline_mid)) / np.mean(baseline_mid)\n",
    "                data_y_all[subj][stim][feat] = np.zeros([len(data_all[subj][stim][feat]), 1])\n",
    "\n",
    "            if stim == 1:\n",
    "                data_all[subj][stim][feat] = (feature_mid - np.mean(baseline_mid)) / np.mean(baseline_mid)\n",
    "                data_y_all[subj][stim][feat] = np.ones([len(data_all[subj][stim][feat]), 1])\n",
    "\n",
    "data_all_1 = []\n",
    "data_y_all_1 = []\n",
    "\n",
    "for feat in range(NumFeat):\n",
    "    temp_data_stim = []\n",
    "    temp_labels_stim = []\n",
    "\n",
    "    for stim in range(2):\n",
    "        temp_data = []\n",
    "        temp_labels = []\n",
    "\n",
    "        for subj in range(len(subj_list)):\n",
    "            temp_data.extend(data_all[subj][stim][feat])\n",
    "            temp_labels.extend(data_y_all[subj][stim][feat])\n",
    "\n",
    "        temp_data_stim.extend(temp_data)\n",
    "        temp_labels_stim.extend(temp_labels)\n",
    "\n",
    "    data_all_1.append(temp_data_stim)\n",
    "    data_y_all_1.append(temp_labels_stim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0]], [[0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0]], [[0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0]], [[0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0]], [[0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0]], [[0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0]], [[0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0]], [[0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0]], [[0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0]], [[0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0]], [[0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0]], [[0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0]], [[0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0]], [[0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0]], [[0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0]], [[0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0]], [[0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0]], [[0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0]], [[0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0]], [[0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0]], [[0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0]], [[0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0]], [[0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0]], [[0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0]], [[0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0]], [[0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0]], [[0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0]], [[0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0]], [[1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1]], [[1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1]], [[1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1]], [[1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1]], [[1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1]], [[1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1]], [[1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1]], [[1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1]], [[1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1]]]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(data_labels)\n",
    "print(data_labels[0][0][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
